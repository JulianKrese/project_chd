{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b1bace51-d646-4ab1-abdf-4e2e65a091c8",
      "metadata": {
        "id": "b1bace51-d646-4ab1-abdf-4e2e65a091c8"
      },
      "source": [
        "# Models Work"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r project_chd/"
      ],
      "metadata": {
        "id": "VZ1hUpx1MFWn"
      },
      "id": "VZ1hUpx1MFWn",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/JulianKrese/project_chd/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnMJaWECxAxe",
        "outputId": "7b05d7c8-685d-41ed-b652-66b3f50bc674"
      },
      "id": "AnMJaWECxAxe",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'project_chd'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 79 (delta 26), reused 2 (delta 2), pack-reused 29\u001b[K\n",
            "Receiving objects: 100% (79/79), 2.05 MiB | 6.49 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "nlgQ2ldgxVPG"
      },
      "id": "nlgQ2ldgxVPG",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting training sets\n",
        "X_train = pd.read_csv(\"/content/project_chd/X_train_cleaned.csv\")\n",
        "y_train = pd.read_csv(\"/content/project_chd/y_train_cleaned.csv\")\n",
        "\n",
        "# getting test sets\n",
        "X_test = pd.read_csv(\"/content/project_chd/X_test_cleaned.csv\")\n",
        "y_test = pd.read_csv(\"/content/project_chd/y_test_cleaned.csv\")"
      ],
      "metadata": {
        "id": "zoCJuq2TxaSQ"
      },
      "id": "zoCJuq2TxaSQ",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep track of all R-squared values found\n",
        "R_squared_vals = {}"
      ],
      "metadata": {
        "id": "xpJS8Pk2eXcy"
      },
      "id": "xpJS8Pk2eXcy",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create kNN model - k of 1 gives the highest R-squared\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_train, y_train.values.ravel()) # .values.ravel() suppresses data conversion warning - converts column vector to 1d array\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"kNN R^2:\", abs(r2))\n",
        "R_squared_vals[\"kNN\"] = abs(r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXTznQ3gw6Lb",
        "outputId": "f3172b24-d8c7-4220-d2e9-490b06e095f4"
      },
      "id": "xXTznQ3gw6Lb",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kNN R^2: 0.8478334119549835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create decision tree - depth of 24 gives the highest R-squared\n",
        "dt = DecisionTreeClassifier(max_depth=24, random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"Decision tree R^2:\", abs(r2))\n",
        "R_squared_vals[\"Decision tree\"] = abs(r2)"
      ],
      "metadata": {
        "id": "q7gZdi2sM4gW",
        "outputId": "d62c1022-1950-43a1-e14e-2348622fed79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "q7gZdi2sM4gW",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree R^2: 0.8742310321257691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8yzZ57XtmyC-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yzZ57XtmyC-",
        "outputId": "c202912d-24dc-4b9b-aeb9-811f4080f669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 (all variables) =  0.09069686607234828\n",
            "R^2 (min-max normalized):  0.09069686607234895\n"
          ]
        }
      ],
      "source": [
        "# trying linear regression with all variables\n",
        "stock_reg = LinearRegression().fit(X_train, y_train)\n",
        "r2 = abs(stock_reg.score(X_test, y_test))\n",
        "print(\"R^2 (all variables) = \", r2)\n",
        "R_squared_vals[\"Linear regression\"] = r2\n",
        "\n",
        "# trying linear regression with min-max normalizing\n",
        "scaler = MinMaxScaler()\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "norm_reg = LinearRegression().fit(X_train_norm, y_train)\n",
        "r2 = abs(norm_reg.score(X_test_norm, y_test))\n",
        "print(\"R^2 (min-max normalized): \", r2)\n",
        "R_squared_vals[\"Max-min normalized\"] = r2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trying linear regression with different correlated variables (finds col w/ highest R-squared)\n",
        "corr_matrix = X_train.corr()\n",
        "best_r2 = 0\n",
        "best_col = \"\"\n",
        "for col in corr_matrix:\n",
        "  high_corr_vars = corr_matrix.index[abs(corr_matrix[col]) > 0.5]\n",
        "  X_train_corr = X_train[high_corr_vars]\n",
        "  X_test_corr = X_test[high_corr_vars]\n",
        "  corr_reg = LinearRegression().fit(X_train_corr, y_train)\n",
        "  r2 = abs(corr_reg.score(X_test_corr, y_test))\n",
        "  if r2 > best_r2:\n",
        "    best_r2 = r2\n",
        "    best_col = col\n",
        "print(f\"R^2 (correlated vars on {best_col}): {best_r2}\")\n",
        "R_squared_vals[f\"Correlated vars on {best_col}\"] = best_r2"
      ],
      "metadata": {
        "id": "CNKxOMKobITS",
        "outputId": "724b1065-2b7b-43d9-dfd9-a3e286e66b55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CNKxOMKobITS",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 (correlated vars on prevalentHyp): 0.06374168477694897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trying linear regression with polynomial expanders (tests multiple degrees to find best R-squared)\n",
        "best_r2 = 0\n",
        "best_degree = 0\n",
        "for d in range(4):\n",
        "  poly = PolynomialFeatures(degree=d)\n",
        "  X_train_poly = poly.fit_transform(X_train)\n",
        "  X_test_poly = poly.transform(X_test)\n",
        "  poly_reg = LinearRegression().fit(X_train_poly, y_train)\n",
        "  r2 = abs(poly_reg.score(X_test_poly, y_test))\n",
        "  if (r2 > best_r2) and (r2 <= 1):\n",
        "    best_r2 = r2\n",
        "    best_degree = d\n",
        "print(f\"R^2 (polynomial features, degree={best_degree}): \", best_r2)\n",
        "R_squared_vals[\"Polynomial expanders\"] = best_r2"
      ],
      "metadata": {
        "id": "poVRqMWBbKLV",
        "outputId": "b5585649-db93-4c21-d4aa-a7c938199b0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "poVRqMWBbKLV",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 (polynomial features, degree=1):  0.09069686607234839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print all R-squared vals found\n",
        "print(R_squared_vals)"
      ],
      "metadata": {
        "id": "2ycYE2ENfKiB",
        "outputId": "c580481d-6098-4677-8435-5ef48ee6c850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2ycYE2ENfKiB",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'kNN': 0.8478334119549835, 'Decision tree': 0.8742310321257691, 'Linear regression': 0.09069686607234828, 'Max-min normalized': 0.09069686607234895, 'Correlated vars on prevalentHyp': 0.06374168477694897, 'Polynomial expanders': 0.09069686607234839}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find max\n",
        "max(R_squared_vals.items(), key=lambda k: k[1])"
      ],
      "metadata": {
        "id": "XQk4TV6CgLkw",
        "outputId": "6c1c5ee6-b899-4fb2-ec1a-57a3cc04c17d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XQk4TV6CgLkw",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Decision tree', 0.8742310321257691)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears that the most effective form of predictive algorithm is the Decision Tree Classifier, with the R^2 value coming out to be 0.87 after training at a max depth of 24."
      ],
      "metadata": {
        "id": "7Vo1U3AvgXlN"
      },
      "id": "7Vo1U3AvgXlN"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}