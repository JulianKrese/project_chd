{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b1bace51-d646-4ab1-abdf-4e2e65a091c8",
      "metadata": {
        "id": "b1bace51-d646-4ab1-abdf-4e2e65a091c8"
      },
      "source": [
        "# Models Work"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r project_chd/"
      ],
      "metadata": {
        "id": "VZ1hUpx1MFWn",
        "outputId": "c3cf60d2-e27e-4ba4-bd97-3d135bef5fce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VZ1hUpx1MFWn",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'project_chd/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/JulianKrese/project_chd/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnMJaWECxAxe",
        "outputId": "4c835fa7-462e-40cd-e597-d93eb4119955"
      },
      "id": "AnMJaWECxAxe",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'project_chd'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 76 (delta 24), reused 2 (delta 2), pack-reused 29\u001b[K\n",
            "Receiving objects: 100% (76/76), 2.05 MiB | 5.20 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "nlgQ2ldgxVPG"
      },
      "id": "nlgQ2ldgxVPG",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting training sets\n",
        "X_train = pd.read_csv(\"/content/project_chd/X_train_cleaned.csv\")\n",
        "y_train = pd.read_csv(\"/content/project_chd/y_train_cleaned.csv\")\n",
        "\n",
        "# getting test sets\n",
        "X_test = pd.read_csv(\"/content/project_chd/X_test_cleaned.csv\")\n",
        "y_test = pd.read_csv(\"/content/project_chd/y_test_cleaned.csv\")"
      ],
      "metadata": {
        "id": "zoCJuq2TxaSQ"
      },
      "id": "zoCJuq2TxaSQ",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create kNN model - k of 1 gives the highest R-squared\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "# Fit model\n",
        "knn.fit(X_train, y_train.values.ravel()) # .values.ravel() suppresses data conversion warning - converts column vector to 1d array\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"kNN R^2:\", abs(r2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXTznQ3gw6Lb",
        "outputId": "0cf899d2-8f82-4bc1-87a4-521cc04527a4"
      },
      "id": "xXTznQ3gw6Lb",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kNN R^2: 0.8478334119549835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create decision tree - depth of 24 gives the highest R-squared\n",
        "dt = DecisionTreeClassifier(max_depth=24, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R^2:\", abs(r2))"
      ],
      "metadata": {
        "id": "q7gZdi2sM4gW",
        "outputId": "0364afbe-3b1f-4eee-e579-c5e1cde14b20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "q7gZdi2sM4gW",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2: 0.8742310321257691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8yzZ57XtmyC-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yzZ57XtmyC-",
        "outputId": "d7c2cb4c-c079-4242-9059-e1d9b9ecc99e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 (all variables) =  0.09069686607234828\n",
            "R^2 (min-max normalized):  0.09069686607234895\n",
            "R^2 (correlated variables):  0.009601962516968432\n",
            "R^2 (polynomial features, degree 2):  0.014284325836945277\n"
          ]
        }
      ],
      "source": [
        "# trying linear regression with all variables\n",
        "stock_reg = LinearRegression().fit(X_train, y_train)\n",
        "print(\"R^2 (all variables) = \", stock_reg.score(X_test, y_test))\n",
        "\n",
        "# trying linear regression with min-max normalizing\n",
        "scaler = MinMaxScaler()\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "norm_reg = LinearRegression().fit(X_train_norm, y_train)\n",
        "print(\"R^2 (min-max normalized): \", norm_reg.score(X_test_norm, y_test))\n",
        "\n",
        "# trying linear regression with choosing correlated variables\n",
        "corr_matrix = X_train.corr()\n",
        "high_corr_vars = corr_matrix.index[abs(corr_matrix[\"BMI\"]) > 0.5]\n",
        "X_train_corr = X_train[high_corr_vars]\n",
        "X_test_corr = X_test[high_corr_vars]\n",
        "\n",
        "corr_reg = LinearRegression().fit(X_train_corr, y_train)\n",
        "print(\"R^2 (correlated variables): \", corr_reg.score(X_test_corr, y_test))\n",
        "\n",
        "# trying linear regression with polynomial expanders (probably want to test multiple degrees)\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "poly_reg = LinearRegression().fit(X_train_poly, y_train)\n",
        "print(\"R^2 (polynomial features, degree 2): \", poly_reg.score(X_test_poly, y_test))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}